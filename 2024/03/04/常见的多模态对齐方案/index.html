<!DOCTYPE html>
<html lang="zh">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="google-site-verification" content="BTo06tdvlac_Dho4-PFTLmDqjKXr1KtOzavpD8XDA5k" />
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 7.0.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.0/css/all.min.css" integrity="sha256-yIDrPSXHZdOZhAqiBP7CKzIwMQmRCJ8UeB8Jo17YC4o=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"jiechu520.github.io","root":"/","images":"/images","scheme":"Muse","darkmode":false,"version":"8.19.1","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"}}</script><script src="/js/config.js"></script>

    <meta name="description" content="常见的多模态对齐方案1、背景LLM 只具备处理文本的能力，需要弥补自然语言和图像模态之间的差距。通过端到端的方式训练 LMM 代价非常高，并且可能会带来灾难性遗忘的风险。目前，通常的做法是基于预训练的视觉编码器和 LLM 来构建 VLM。图像生成领域，也通过类似模态对齐的结构来引入额外的信息控制生成。常见的模态对齐方案，主要分为以下两类：  基于 Learnable Query 的方案，包括： P">
<meta property="og:type" content="article">
<meta property="og:title" content="常见的多模态对齐方案">
<meta property="og:url" content="https://jiechu520.github.io/2024/03/04/%E5%B8%B8%E8%A7%81%E7%9A%84%E5%A4%9A%E6%A8%A1%E6%80%81%E5%AF%B9%E9%BD%90%E6%96%B9%E6%A1%88/index.html">
<meta property="og:site_name" content="CJ blog">
<meta property="og:description" content="常见的多模态对齐方案1、背景LLM 只具备处理文本的能力，需要弥补自然语言和图像模态之间的差距。通过端到端的方式训练 LMM 代价非常高，并且可能会带来灾难性遗忘的风险。目前，通常的做法是基于预训练的视觉编码器和 LLM 来构建 VLM。图像生成领域，也通过类似模态对齐的结构来引入额外的信息控制生成。常见的模态对齐方案，主要分为以下两类：  基于 Learnable Query 的方案，包括： P">
<meta property="og:locale">
<meta property="og:image" content="https://vino-1316924433.cos.ap-beijing.myqcloud.com/image-20240303234925136.png">
<meta property="og:image" content="https://vino-1316924433.cos.ap-beijing.myqcloud.com/v2-85dfc577f695db6f8432cc7b4f114448_r.jpg">
<meta property="og:image" content="https://vino-1316924433.cos.ap-beijing.myqcloud.com/%E6%88%AA%E5%B1%8F2024-03-04%2000.07.50.png">
<meta property="article:published_time" content="2024-03-04T13:00:00.000Z">
<meta property="article:modified_time" content="2024-03-04T15:08:00.000Z">
<meta property="article:author" content="Jie Chu">
<meta property="article:tag" content="BLIP2">
<meta property="article:tag" content="Q-fromer">
<meta property="article:tag" content="Cross-attention">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://vino-1316924433.cos.ap-beijing.myqcloud.com/image-20240303234925136.png">


<link rel="canonical" href="https://jiechu520.github.io/2024/03/04/%E5%B8%B8%E8%A7%81%E7%9A%84%E5%A4%9A%E6%A8%A1%E6%80%81%E5%AF%B9%E9%BD%90%E6%96%B9%E6%A1%88/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh","comments":true,"permalink":"https://jiechu520.github.io/2024/03/04/%E5%B8%B8%E8%A7%81%E7%9A%84%E5%A4%9A%E6%A8%A1%E6%80%81%E5%AF%B9%E9%BD%90%E6%96%B9%E6%A1%88/","path":"2024/03/04/常见的多模态对齐方案/","title":"常见的多模态对齐方案"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>常见的多模态对齐方案 | CJ blog</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">CJ blog</p>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">不知名算法工程师</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="Search" role="button">
    </div>
  </div>
</div>







</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%B8%B8%E8%A7%81%E7%9A%84%E5%A4%9A%E6%A8%A1%E6%80%81%E5%AF%B9%E9%BD%90%E6%96%B9%E6%A1%88"><span class="nav-number">1.</span> <span class="nav-text">常见的多模态对齐方案</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1%E3%80%81%E8%83%8C%E6%99%AF"><span class="nav-number">1.1.</span> <span class="nav-text">1、背景</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2%E3%80%81%E6%A8%A1%E6%80%81%E5%AF%B9%E9%BD%90%E7%9A%84%E6%96%B9%E6%A1%88"><span class="nav-number">1.2.</span> <span class="nav-text">2、模态对齐的方案</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#2-1-Cross-attention"><span class="nav-number">1.2.1.</span> <span class="nav-text">2.1 Cross attention</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-2-Percevier-Resampler"><span class="nav-number">1.2.2.</span> <span class="nav-text">2.2 Percevier Resampler</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-3-Q-former"><span class="nav-number">1.2.3.</span> <span class="nav-text">2.3 Q-former</span></a></li></ol></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Jie Chu</p>
  <div class="site-description" itemprop="description">日常笔记</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">18</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">5</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">30</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh">
    <link itemprop="mainEntityOfPage" href="https://jiechu520.github.io/2024/03/04/%E5%B8%B8%E8%A7%81%E7%9A%84%E5%A4%9A%E6%A8%A1%E6%80%81%E5%AF%B9%E9%BD%90%E6%96%B9%E6%A1%88/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Jie Chu">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="CJ blog">
      <meta itemprop="description" content="日常笔记">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="常见的多模态对齐方案 | CJ blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          常见的多模态对齐方案
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>
      

      <time title="Created: 2024-03-04 21:00:00 / Modified: 23:08:00" itemprop="dateCreated datePublished" datetime="2024-03-04T21:00:00+08:00">2024-03-04</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%A4%9A%E6%A8%A1%E6%80%81/" itemprop="url" rel="index"><span itemprop="name">多模态</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><h1 id="常见的多模态对齐方案"><a href="#常见的多模态对齐方案" class="headerlink" title="常见的多模态对齐方案"></a>常见的多模态对齐方案</h1><h2 id="1、背景"><a href="#1、背景" class="headerlink" title="1、背景"></a>1、背景</h2><p>LLM 只具备处理文本的能力，需要弥补自然语言和图像模态之间的差距。通过端到端的方式训练 LMM 代价非常高，并且可能会带来灾难性遗忘的风险。目前，通常的做法是基于预训练的视觉编码器和 LLM 来构建 VLM。图像生成领域，也通过类似模态对齐的结构来引入额外的信息控制生成。常见的模态对齐方案，主要分为以下两类：</p>
<ul>
<li>基于 Learnable Query 的方案，包括：<ul>
<li>Perceiver Resampler</li>
<li>Q-Former</li>
<li>Cross-attention</li>
</ul>
</li>
<li>基于 Projection 的方案：<ul>
<li>单层 Linear 投影</li>
<li>两层 MLP</li>
</ul>
</li>
</ul>
<h2 id="2、模态对齐的方案"><a href="#2、模态对齐的方案" class="headerlink" title="2、模态对齐的方案"></a>2、模态对齐的方案</h2><h3 id="2-1-Cross-attention"><a href="#2-1-Cross-attention" class="headerlink" title="2.1 Cross attention"></a>2.1 Cross attention</h3><p>很多常见的模块的使用了 Cross attention，大多数文生图模型，text embedding 就是通过 cross attention 引入到 Unet 结构里面。</p>
<p>假设输入的 Query embedding 维度 32 x 768，输入的 image embedding 维度 257 x 1024 为例，如下所示，可以看出 Cross Attention 的过程，K 和 V 的维度为 1024 x 768，Q 的维度为 768 x 768，所以对应的 Attention Score 的维度为 32 x 257，最终也可以保持 Query embedding 维度不变，依然为 32 x 768（红框）：</p>
<p><img src="https://vino-1316924433.cos.ap-beijing.myqcloud.com/image-20240303234925136.png" alt="image-20240303234925136"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">CrossAttention</span>(nn.Module):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    A cross attention layer.</span></span><br><span class="line"><span class="string">    Parameters:</span></span><br><span class="line"><span class="string">        query_dim (`int`): The number of channels in the query.</span></span><br><span class="line"><span class="string">        cross_attention_dim (`int`, *optional*):</span></span><br><span class="line"><span class="string">            The number of channels in the encoder_hidden_states. If not given, defaults to `query_dim`.</span></span><br><span class="line"><span class="string">        heads (`int`,  *optional*, defaults to 8): The number of heads to use for multi-head attention.</span></span><br><span class="line"><span class="string">        dim_head (`int`,  *optional*, defaults to 64): The number of channels in each head.</span></span><br><span class="line"><span class="string">        dropout (`float`, *optional*, defaults to 0.0): The dropout probability to use.</span></span><br><span class="line"><span class="string">        bias (`bool`, *optional*, defaults to False):</span></span><br><span class="line"><span class="string">            Set to `True` for the query, key, and value linear layers to contain a bias parameter.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    query = attn.to_q(hidden_states)</span><br><span class="line">    query = attn.head_to_batch_dim(query)</span><br><span class="line"></span><br><span class="line">    encoder_hidden_states = encoder_hidden_states <span class="keyword">if</span> encoder_hidden_states <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">else</span> hidden_states</span><br><span class="line">    key = attn.to_k(encoder_hidden_states)</span><br><span class="line">    value = attn.to_v(encoder_hidden_states)</span><br><span class="line">    key = attn.head_to_batch_dim(key)</span><br><span class="line">    value = attn.head_to_batch_dim(value)</span><br><span class="line"></span><br><span class="line">    attention_probs = attn.get_attention_scores(query, key, attention_mask)</span><br><span class="line">    hidden_states = torch.bmm(attention_probs, value)</span><br></pre></td></tr></table></figure>
<p>使用 Cross attention 作为模态间对齐结构的 VLM 有：</p>
<ul>
<li>Qwen-VL</li>
<li>各种文生图模型</li>
</ul>
<h3 id="2-2-Percevier-Resampler"><a href="#2-2-Percevier-Resampler" class="headerlink" title="2.2 Percevier Resampler"></a>2.2 Percevier Resampler</h3><p><img src="https://vino-1316924433.cos.ap-beijing.myqcloud.com/v2-85dfc577f695db6f8432cc7b4f114448_r.jpg" alt="img"></p>
<p>Resampler 的结构如上图所示，可以看出它是一个常规的 transformer block， 其中 attention 使用 Cross attention，拿 Flamingo 举例，具体来说：</p>
<ul>
<li>每个图像经 Vision Encoder 会生成一个 [S, d] 的视觉特征，T 个图像对应 x_f 的维度为 [T, S, d]</li>
<li>x_f 加上维度为 [T, 1, d] 的 time_embeddings</li>
<li>将时间和空间维度拉平，x_f -&gt; [T*S, d]</li>
<li>将 x_f 作为 transformer block 的 Key 和 Value 输入</li>
<li>自定义的 R 个可学习的 Query Token，对应维度为 [R, d]</li>
<li>然后经过 num_layers 层 transformer block 得到对应的新的视觉特征 x，维度为 [R, d]，和可学习的 Query 维度一致。</li>
</ul>
<p>使用 Resampler 结构的常见 VLM 模型有：</p>
<ul>
<li>Flamingo</li>
<li>mPLUG-Owl</li>
</ul>
<h3 id="2-3-Q-former"><a href="#2-3-Q-former" class="headerlink" title="2.3 Q-former"></a>2.3 Q-former</h3><p>Q-former 结构由 BLIP2 模型提出来的，在 Q-Former 中，作者额外创建了一组可学习的 Query embedding 作为输入（这与 Flamingo 中R 个可学习的 Query Token 作用一样）。这些 Query embedding 在 Self Attention 层相互交叉，并通过 Cross attention 层（每隔一个 transformer block 有一个 Cross attention）与冻结的 image encoder 输出的 image embedding 进行交叉。</p>
<p><img src="https://vino-1316924433.cos.ap-beijing.myqcloud.com/%E6%88%AA%E5%B1%8F2024-03-04%2000.07.50.png" alt="截屏2024-03-04 00.07.50"></p>
<p>使用 Q-former 结构的 VLM 模型有：</p>
<ul>
<li>BLIP2</li>
<li>MiniGPT- v1</li>
<li>InstructBILP</li>
</ul>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/BLIP2/" rel="tag"># BLIP2</a>
              <a href="/tags/Q-fromer/" rel="tag"># Q-fromer</a>
              <a href="/tags/Cross-attention/" rel="tag"># Cross-attention</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2024/02/09/%E5%9B%BE%E5%83%8F%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B%E7%BB%BC%E8%BF%B0/" rel="prev" title="图像生成模型综述">
                  <i class="fa fa-angle-left"></i> 图像生成模型综述
                </a>
            </div>
            <div class="post-nav-item">
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2024</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">Jie Chu</span>
  </div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/muse/" rel="noopener" target="_blank">NexT.Muse</a>
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script>

  






  




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>



</body>
</html>
