<!DOCTYPE html>
<html lang="zh">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="google-site-verification" content="BTo06tdvlac_Dho4-PFTLmDqjKXr1KtOzavpD8XDA5k" />
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 7.0.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.0/css/all.min.css" integrity="sha256-yIDrPSXHZdOZhAqiBP7CKzIwMQmRCJ8UeB8Jo17YC4o=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"jiechu520.github.io","root":"/","images":"/images","scheme":"Muse","darkmode":false,"version":"8.19.1","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"}}</script><script src="/js/config.js"></script>

    <meta name="description" content="日常笔记">
<meta property="og:type" content="website">
<meta property="og:title" content="CJ blog">
<meta property="og:url" content="https://jiechu520.github.io/page/2/index.html">
<meta property="og:site_name" content="CJ blog">
<meta property="og:description" content="日常笔记">
<meta property="og:locale">
<meta property="article:author" content="Jie Chu">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="https://jiechu520.github.io/page/2/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":true,"isPost":false,"lang":"zh","comments":"","permalink":"","path":"page/2/index.html","title":""}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>CJ blog</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">CJ blog</h1>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">不知名算法工程师</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="Search" role="button">
    </div>
  </div>
</div>







</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Jie Chu</p>
  <div class="site-description" itemprop="description">日常笔记</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">15</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">4</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">24</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://jiechu520.github.io/2022/06/21/DARN/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Jie Chu">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="CJ blog">
      <meta itemprop="description" content="日常笔记">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | CJ blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/06/21/DARN/" class="post-title-link" itemprop="url">图片美观度模型</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2022-06-21 21:00:00" itemprop="dateCreated datePublished" datetime="2022-06-21T21:00:00+08:00">2022-06-21</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2022-06-22 23:08:00" itemprop="dateModified" datetime="2022-06-22T23:08:00+08:00">2022-06-22</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/CV/" itemprop="url" rel="index"><span itemprop="name">CV</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="360图片搜索—图片美观度模型"><a href="#360图片搜索—图片美观度模型" class="headerlink" title="360图片搜索—图片美观度模型"></a>360图片搜索—图片美观度模型</h1><p><a target="_blank" rel="noopener" href="https://github.com/lmm360/Image-aesthetic-assessment">code和数据集地址</a></p>
<h2 id="一、背景"><a href="#一、背景" class="headerlink" title="一、背景"></a>一、背景</h2><p>在图片搜索中，用户希望搜索的图片不但和自己的查询相关，并且在视觉感官、图片质量等方面也要比较满意。此时，就需要我们计算图片图片的在美学上的特征分值，加到排序模型中，将高相关性、高美学质量的图像排在检索结果的前面。</p>
<p>但是现有的图片质量模型主要考虑图像的质量，如像素，清晰度、有无噪声，在图像的美学特征，如构图、色彩、内容和谐等考虑的权重偏低。</p>
<h2 id="二、相关研究"><a href="#二、相关研究" class="headerlink" title="二、相关研究"></a>二、相关研究</h2><p>大部分的工作将这种美观度评估的任务形式化为回归或者分类问题。开源的数据集有 AVA【1】, AADB【2】等。代表的工作有 NIMA模型【3】和DARN模型【4】。360美观度模型正是在DARN模型的基础上改进得到的。</p>
<p><strong>NIMA模型</strong>利用了AVA数据集，AVA数据集包含了约 25w张图像，由业余摄影师根据审美品质进行评分，200人评分的平均分就是该张图像的最终的分数。</p>
<p><strong>NIMA模型</strong>目标是预测与人类评分的相关性，而不是将图片分类或者回归到平均分。提出了<strong>EMD loss</strong>，它显示了有序类分类的性能提升。下面是模型结构。</p>
<p><img src="https://vino-1316924433.cos.ap-beijing.myqcloud.com/image-20231026144748579.png" alt="image-20231026144748579"></p>
<p>开源的数据集AVA、AADB图像与图片搜索的图像在种类和美学质量分布上有很大的差异，所以不能再公开的数据集上训练模型。最好的方式使构建自己的数据集，但是像AVA数据集的构建，需要一批具有美学专业知识的标注人员对每张图片进行标注。标注成本和难度都有很大</p>
<p>Microsoft提出了<a href="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1805.00309">《An Universal Image Attractiveness Ranking Framework》</a>，很好的解决美学数据集构建难的问题，并提出了新的美学模型——DARN模型。下面介绍DARN模型以及360美观度模型在此之上的改进。</p>
<h2 id="三、基于DARN的美观度模型"><a href="#三、基于DARN的美观度模型" class="headerlink" title="三、基于DARN的美观度模型"></a>三、基于DARN的美观度模型</h2><h3 id="1、数据集构建"><a href="#1、数据集构建" class="headerlink" title="1、数据集构建"></a>1、数据集构建</h3><p>数据集的构建过程如下：</p>
<p>1、在图片搜索中高中低频queey中各选择2000条query。</p>
<p>2、根据query在图片搜索返回结果中，top20里面，top40-60里面各抽取两张图片。</p>
<p>3、根据Swiss-system tournament规则、对这4张图像进行三轮标注。</p>
<p>4、每一轮标注，将同一query下4张图片组成两对，每一对图像由7个人标注人员去进行投票：</p>
<p>左边更好，左边好一点，一样好，右边好一点，右边更好。</p>
<p>具体标注可以参考下图：</p>
<p><img src="https://vino-1316924433.cos.ap-beijing.myqcloud.com/image-20231026154542693.png" alt="image-20231026154542693"></p>
<p>这样标注的好处是，标注人员无需掌握专业知识，“比较”相对于给出一个直接的分值更简单，多人投票也降低主观偏好带来的偏差。7个标注人员对image1和image2进行投票的结果中，左边更好，左边好一点，一样好，右边好一点，右边更好的人数分别为0、1、1、4、1，则这对图像的label为：</p>
<script type="math/tex; mode=display">
l(image1,image2)=(0,1,1,4,1)</script><h3 id="2、DARN模型"><a href="#2、DARN模型" class="headerlink" title="2、DARN模型"></a>2、DARN模型</h3><p>我们的标注数据是pair对，模型结构如下：</p>
<p><img src="https://vino-1316924433.cos.ap-beijing.myqcloud.com/image-20231026163835872.png" alt="image-20231026163835872"></p>
<p>左边的网络和右边的网络是参数共享的，图像对输入到网络中，经过 Deep CNN（如resnet50）的特征抽取，再经过三个fc层，然后计算最终输出的方差和均值。</p>
<p>假设每张图像都是由很多的专业的美学专家评分得到的，那么根据中心极限定理，图像美观度分值$X$服从正态分布，AVA数据基本就符合正态分布。所以<strong>最终计算得到的均值和方差就可以看作是模型计算的该图像的平均美观度分值和方差</strong>。</p>
<p>对于一个pair对 $[x_i,x_j]$, 它们的 label 记为${0,1,2,3,4}$ 分别对应着左边更好，左边好一点，一样好，右边好一点，右边更好。对于我们的标注数据有：</p>
<script type="math/tex; mode=display">
\sum_{y=0}^4{P_{ij}(xi-xj)=y}=1</script><p>直觉上，图像通过模型得到的美观度分值有以下两个特点：</p>
<ul>
<li>图像越美观，模型得到美观度分数均值越大。</li>
<li>图像对的label应该与美观度分数一致。如，$u_i&gt;&gt;u_j$,那么标注图像 $i$ 好一点或者更好的人数应该更多。如果 $u_i=u_j$,则大部分人标注的 label 是 “一样好”。</li>
</ul>
<p>上面说到我们假设美观度分值服从正态分布，那么两个美观度分值的差也服从正态分布，记$x_{i}^{left}$,$x_{j}^{right}$分别表示图像对中左边图像美观度和右边图像美观度（左边和右边只是为了对应我们数据的标注label），他们美观度的差值 $\Delta X$ 服从 $N(x,u_i-u_j,\sigma_{1}^{2}+\sigma_{2}^{2})$。</p>
<p>然后我们定义4个可以学习的边界值 ${b_i}_{i=0}^{3}$，这4个boundaries将 x 轴分成5部分，也就将正态分布和x轴围成的区域分成了5个部分，这5个部分就对应了 我们设定的 五个label {左边更好，左边好一点，一样好，右边好一点，右边更好}，我们定义 $p_{i}^{j}，j={0,1,2,3}$表示第$i$对图像对被标注lable $j$ 的概率。$\Delta u_i $和 $\Delta \sigma_i$ 表示第$i$对图像对美观度分值差的均值和方差。于是我们有：</p>
<script type="math/tex; mode=display">
p_{i}^{j}=\displaystyle \int^{b_j}_{b_{j-1}}N(x;\Delta u_i,\Delta \sigma_i)dx</script><p>形象点可以看下图：</p>
<p><img src="https://vino-1316924433.cos.ap-beijing.myqcloud.com/image-20231026175218691.png" alt="image-20231026175218691"></p>
<p>上面这张图显示了标签如何随着图像对的分数差值系统的变化。当右侧图像的平均得分远高于左侧图像时，得分差的分布将向右移动，导致标签“右侧更好”的概率更高。当左右之间的分数差异变小时，分布向左移动并导致标签发生变化。因此，当两个图像的分数相等时，中间桶中的面积最大，这意味着这对图像最有可能被标记为“一样好”。</p>
<p>至此我们可以计算出模型对第 $i$ 对图像对的美观度分值的差的分布 $p_i=(p_{i}^{0},p_{i}^{1},p_{i}^{2},p_{i}^{3},p_{i}^{4})$ ，而我们</p>
<p>图像对的真实label 为 $l=(n_{i}^{0},n_{i}^{1},n_{i}^{2},n_{i}^{3},n_{i}^{4})$, 因此我们可以定义一个对数最大似然损失函数：</p>
<p><img src="https://vino-1316924433.cos.ap-beijing.myqcloud.com/image-20231026180559585.png" alt="image-20231026180559585"></p>
<p>从上面的过程可以看出，由于预先假设图像的美学评分服从正态分布，而正态分布可以由均值和方差两个参数控制，所以严格的说，DARN模型预测的不是美学评分，而是美学评分分布。<strong>在实际应用时，可以直接用均值作为该图像的美学评分</strong>。</p>
<h3 id="3、实验改进"><a href="#3、实验改进" class="headerlink" title="3、实验改进"></a>3、实验改进</h3><p>实验的过程中，根据我们的数据集和训练情况对DARN模型做了一些改进和调整。</p>
<p>1、 原始DARN模型中，deep CNN以及以后所有FC层，激活函数都是 Relu。缺少带有归一化能力的激活函数和norm操作，则很可能随着<a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=W方差&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra={&quot;sourceType&quot;%3A&quot;article&quot;%2C&quot;sourceId&quot;%3A&quot;83896463&quot;}">W方差</a>的增大，出现个别节点数值过大的问题，导致训练时loss很可能出现nan的情况。所以将第一个FC层的激活函数改为 tanh。</p>
<p>2、在计算均值之前加上softplus激活函数。使得最后推理的结果都是正的，且减小方差。模型中计算正态分布在某一个区间的积分，需要保证 $\sigma &gt;0$，才能让正态分布函数有意义，但是原始论文中：</p>
<p><img src="https://vino-1316924433.cos.ap-beijing.myqcloud.com/image-20231026182412236.png" alt="image-20231026182412236"></p>
<p>使用的是Relu激活函数，有可能训练得到 $\sigma = 0$。</p>
<p>3、训练中对边界值进行截断，防止训练中部分 $\Delta u$过大，产生nan值。</p>
<p>4、最后一层维度通过实验调整为 16。</p>
<p>5、边界值的初始化值对于模型训练影响很大，我们数据集下初始化值为（-0.75，-0.25， 0.25, 0.75）</p>
<p>6、deep CNN 由 resnet50 调整为 swin transformer。</p>
<h2 id="四、结果展示"><a href="#四、结果展示" class="headerlink" title="四、结果展示"></a>四、结果展示</h2><p><img src="https://vino-1316924433.cos.ap-beijing.myqcloud.com/image2022-11-3_15-17-31.png" alt="image2022-11-3_15-17-31"></p>
<p><img src="https://vino-1316924433.cos.ap-beijing.myqcloud.com/image2022-11-3_15-21-28.png" alt="image2022-11-3_15-21-28"></p>
<p><img src="https://vino-1316924433.cos.ap-beijing.myqcloud.com/image2022-11-3_15-24-26.png" alt="image2022-11-3_15-19-28"></p>
<p>该美观度模型计算的特征应用在360图片搜索的排序中，离线ndcg指标和在线Ctr均得到了提升。</p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>【1】N. Murray, L. Marchesotti, and F. Perronnin. Ava: A large-scale database for aesthetic visual analysis. In Computer Vision and Pattern Recognition (CVPR), pages 2408–2415,Providence, RI, USA, 2012. IEEE.</p>
<p>【2】S. Kong, X. Shen, Z. Lin, R. Mech, and C. Fowlkes. Photo aesthetics ranking network with attributes and content adapta-tion. In European Conference on Computer Vision (ECCV),<br>page 662679, Amsterdam, The Netherlands, 2016. Springer.</p>
<p>【3】H. Talebi and P . Milanfar. Nima: Neural image assess-ment. IEEE Transactions on Image Processing, 27:3998–4011, 2017</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://jiechu520.github.io/2022/05/10/NIMA/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Jie Chu">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="CJ blog">
      <meta itemprop="description" content="日常笔记">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | CJ blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/05/10/NIMA/" class="post-title-link" itemprop="url">NIMA——Neural Image Assessment</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2022-05-10 21:00:00" itemprop="dateCreated datePublished" datetime="2022-05-10T21:00:00+08:00">2022-05-10</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2022-05-11 23:08:00" itemprop="dateModified" datetime="2022-05-11T23:08:00+08:00">2022-05-11</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/CV/" itemprop="url" rel="index"><span itemprop="name">CV</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="NIMA：Neural-Image-Assessment"><a href="#NIMA：Neural-Image-Assessment" class="headerlink" title="NIMA：Neural Image Assessment"></a>NIMA：Neural Image Assessment</h1><h2 id="1、introduction"><a href="#1、introduction" class="headerlink" title="1、introduction"></a>1、introduction</h2><ol>
<li><p>基于CNN的方法相比较早期基于手工制作的特征的做法，性能有显著的提升；</p>
</li>
<li><p>AVA 数据集，图片审美视觉分析的标准数据集；</p>
</li>
<li><p>深度CNN非常适合审美评估任务【1】【2】；他们的双列 CNN 由四个卷积层和两个全连接层组成，其输入是调整大小的图像和大小为 224 × 224 的裁剪窗口；</p>
</li>
<li><p>之前大多是通过分类或者回归的方法预测人类评估的分数；</p>
</li>
<li><p>kong【3】训练了一个基于 AlexNet 的 CNN 来学习两个输入图像的审美分数差异，从而间接优化排名相关性。</p>
</li>
<li><p>NIMA的目标是预测与人类评分的相关性，而不是将图片分类或者回归到平均分。提出了EMD loss，它显示了有序类分类的性能提升。实验也表明，这种方法也更准确地预测了平均分。</p>
</li>
</ol>
<h2 id=""><a href="#" class="headerlink" title=" "></a> </h2><h2 id="2、proposed-method"><a href="#2、proposed-method" class="headerlink" title="2、proposed method"></a>2、proposed method</h2><p>模型建立在图片分类模型的结构基础上。</p>
<p><img src="https://vino-1316924433.cos.ap-beijing.myqcloud.com/image-20231026114849878.png" alt="image-20231026114849878"></p>
<p>在训练阶段，输入图像被重新缩放为256<em>256，然后随机提取 224\</em>224的裁剪，这减少潜在的过度拟合问题。</p>
<h2 id="3、实验"><a href="#3、实验" class="headerlink" title="3、实验"></a>3、实验</h2><p>基线CNN权重通过在ImageNet上训练来初始化，最后一个全连接层是随机初始化。权重和偏置动量设置为0.9,基线CNN最后一层dropout应用0.75。基线CNN层和最后一个全连接层的学习率分别设置为3<em>10e-7,3\</em>10e-6。在基线CNN层上设置较低的学习率会导致使用sgd时更容易和更快优化。</p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>【1】Deep multi-patch aggregation network for image style, aesthetics, and quality estimation</p>
<p>【2】Rating image aesthetics using deep learning</p>
<p>【3】S. Kong, X. Shen, Z. Lin, R. Mech, and C. Fowlkes, “Photo aesthetics ranking network with attributes and content adaptation,” in European Conference on Computer Vision. Springer, 2016, pp. 662–679. 1, 2, 6, 7</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://jiechu520.github.io/2022/04/19/Vit/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Jie Chu">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="CJ blog">
      <meta itemprop="description" content="日常笔记">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | CJ blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/04/19/Vit/" class="post-title-link" itemprop="url">VIT</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>
      

      <time title="Created: 2022-04-19 21:00:00 / Modified: 23:08:00" itemprop="dateCreated datePublished" datetime="2022-04-19T21:00:00+08:00">2022-04-19</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/CV/" itemprop="url" rel="index"><span itemprop="name">CV</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="ViT-Vision-Transformer"><a href="#ViT-Vision-Transformer" class="headerlink" title="ViT(Vision Transformer)"></a>ViT(Vision Transformer)</h1><h2 id="模型介绍"><a href="#模型介绍" class="headerlink" title="模型介绍"></a>模型介绍</h2><p>受到NLP领域中Transformer成功应用的启发，Vit算法中尝试将标准的Transformer结构直接应用于图像，并对整个图像分类流程进行最少的修改。</p>
<p><strong>Vit原论文中最核心的结论是，当拥有足够多的数据进行预训练的时候，ViT的表现就会超过CNN，突破Transformer的归纳偏置的限制，可以在下游任务中获得较好的迁移效果。</strong></p>
<p>但是当训练数据集不够大的时候，ViT的表现通常比同等大小的ResNets要差一些，因为Transformer和CNN相比缺少归纳偏置（inductive bias），即一种先验知识，提前做好的假设。CNN具有两种归纳偏置，一种是局部性（locality/two-dimensional neighborhood structure），即图片上相邻的区域具有相似的特征；一种是平移不变形（translation equivariance）， $f(g(x)=g(f(x)))$ ，其中g代表卷积操作，f代表平移操作。当CNN具有以上两种归纳偏置，就有了很多先验信息，需要相对少的数据就可以学习一个比较好的模型。</p>
<h2 id="模型结构与实现"><a href="#模型结构与实现" class="headerlink" title="模型结构与实现"></a>模型结构与实现</h2><p><img src="https://vino-1316924433.cos.ap-beijing.myqcloud.com/ViT.png" alt="图1 ViT算法结构示意图"></p>
<h3 id="1-图像分块嵌入"><a href="#1-图像分块嵌入" class="headerlink" title="1.图像分块嵌入"></a>1.图像分块嵌入</h3><p>transformer的输入是一个二维矩阵，因此在ViT算法中，首先要做的是如何将一个$H\times W\times C$ 的三维图像转换为$N\times D$ 的二维输入。</p>
<p>iT中的具体实现方式为：将 $H×W×C$ 的图像，变为一个 $N×(P^2\times C)$ 的序列。这个序列可以看作是一系列展平的图像块，也就是将图像切分成小块后，再将其展平。该序列中一共包含了 $N=HW/P^2$ 个图像块，每个图像块的维度则是 $(P^2\times C)$。其中 $P$ 是图像块的大小，$C$ 是通道数量。经过如上变换，就可以将 $N$ 视为sequence的长度了。</p>
<p>但是，此时每个图像块的维度是 $(P2\times C)$，而我们实际需要的向量维度是 $D$，因此我们还需要对图像块进行 Embedding。这里 Embedding 的方式非常简单，只需要对每个 $(P^2\times C)$的图像块做一个线性变换，将维度压缩为 $D$ 即可。</p>
<h3 id="2-多头注意力"><a href="#2-多头注意力" class="headerlink" title="2.多头注意力"></a>2.多头注意力</h3><p>将图像转换成序列之后，就可以将其输入到 Transformer 中结构中进行特征提取了。</p>
<p><img src="https://vino-1316924433.cos.ap-beijing.myqcloud.com/Multi-head_Attention.jpg" alt="图4 多头注意力"></p>
<h3 id="3-MLP"><a href="#3-MLP" class="headerlink" title="3.MLP"></a>3.MLP</h3><p><img src="https://vino-1316924433.cos.ap-beijing.myqcloud.com/MLP.png" alt="图7 多层感知机"></p>
<h3 id="4-DropPath"><a href="#4-DropPath" class="headerlink" title="4.DropPath"></a>4.DropPath</h3><p>除了以上重要模块意外，代码实现过程中还使用了DropPath（Stochastic Depth）来代替传统的Dropout结构，DropPath可以理解为一种特殊的 Dropout。其作用是在训练过程中随机丢弃子图层（randomly drop a subset of layers），而在预测时正常使用完整的 Graph。</p>
<p><strong>参考文献</strong>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2010.11929">An Image is Worth 16x16 Words:Transformers for Image Recognition at Scale</a></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://jiechu520.github.io/2022/04/11/resnet/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Jie Chu">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="CJ blog">
      <meta itemprop="description" content="日常笔记">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | CJ blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/04/11/resnet/" class="post-title-link" itemprop="url">resnet解析</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2022-04-11 21:03:00" itemprop="dateCreated datePublished" datetime="2022-04-11T21:03:00+08:00">2022-04-11</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2023-04-11 23:03:00" itemprop="dateModified" datetime="2023-04-11T23:03:00+08:00">2023-04-11</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/CV/" itemprop="url" rel="index"><span itemprop="name">CV</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="resnet"><a href="#resnet" class="headerlink" title="resnet"></a>resnet</h1><h3 id="1-1-batch-normalization原理"><a href="#1-1-batch-normalization原理" class="headerlink" title="1.1 batch normalization原理"></a>1.1 batch normalization原理</h3><p>提出背景：在训练层数较深的神经网络时，参数的变化导致每一层的输入分布会发生变化，进而上层的网络需要不停地去适应这些分布变化，使得我们的模型训练变得困难——internal Covariate Shift</p>
<p>问题：上层网络需要不停调整来适应输入分布的变化，导致网络学习速度的降低；网络的训练过程容易陷入梯度饱和区，减缓网络收敛速度。</p>
<p>减缓internal covariate shift的方法：</p>
<ul>
<li>白化：对输入数据分布进行变换，具有相同的均值和方差；</li>
<li><strong>batch normalization</strong>：由于白化过程计算成本太高，且改变了网络每一层的分布。</li>
</ul>
<p><img src="https://vino-1316924433.cos.ap-beijing.myqcloud.com/image-20220701153501142.png" alt="image-20220701153501142"></p>
<p><img src="https://vino-1316924433.cos.ap-beijing.myqcloud.com/image-20220701153552148.png" alt="image-20220701153552148"></p>
<h3 id="1-2-resnet-结构"><a href="#1-2-resnet-结构" class="headerlink" title="1.2  resnet 结构"></a>1.2  resnet 结构</h3><p><img src="https://vino-1316924433.cos.ap-beijing.myqcloud.com/image-20220701154852179.png" alt="image-20220701154852179"></p>
<p><strong>Stage 0</strong></p>
<ul>
<li><code>(3,224,224)</code>指输入<code>INPUT</code>的通道数(channel)、高(height)和宽(width)，即<code>(C,H,W)</code>。现假设输入的高度和宽度相等，所以用<code>(C,W,W)</code>表示。</li>
<li>该stage中第1层包括3个先后操作</li>
</ul>
<ol>
<li><code>CONV</code><br> <code>CONV</code>是卷积（Convolution）的缩写，<code>7×7</code>指卷积核大小，<code>64</code>指<a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=卷积核&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra={&quot;sourceType&quot;%3A&quot;article&quot;%2C&quot;sourceId&quot;%3A&quot;353235794&quot;}">卷积核</a>的数量（即该卷积层输出的通道数），<code>/2</code>指卷积核的步长为2。</li>
<li><code>BN</code><br> <code>BN</code>是Batch Normalization的缩写，即常说的BN层。 </li>
<li><code>RELU</code><br> <code>RELU</code>指ReLU激活函数。</li>
</ol>
<ul>
<li><p>该stage中第2层为<code>MAXPOOL</code>，即最大池化层，其kernel大小为<code>3×3</code>、步长为<code>2</code>。</p>
</li>
<li><p><code>(64,56,56)</code>是该stage输出的通道数(channel)、高(height)和宽(width)，其中<code>64</code>等于该stage第1层卷积层中卷积核的数量，<code>56</code>等于<code>224/2/2</code>（步长为2会使输入尺寸减半）。 </p>
</li>
</ul>
<p>总体来讲，在<em>Stage 0</em>中，形状为<code>(3,224,224)</code>的输入先后经过卷积层、<a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=BN层&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra={&quot;sourceType&quot;%3A&quot;article&quot;%2C&quot;sourceId&quot;%3A&quot;353235794&quot;}">BN层</a>、ReLU激活函数、<a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=MaxPooling层&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra={&quot;sourceType&quot;%3A&quot;article&quot;%2C&quot;sourceId&quot;%3A&quot;353235794&quot;}">MaxPooling层</a>得到了形状为<code>(64,56,56)</code>的输出。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://jiechu520.github.io/2022/03/20/Inception%E7%B3%BB%E5%88%97/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Jie Chu">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="CJ blog">
      <meta itemprop="description" content="日常笔记">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | CJ blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/03/20/Inception%E7%B3%BB%E5%88%97/" class="post-title-link" itemprop="url">Inception系列</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2022-03-20 11:03:00" itemprop="dateCreated datePublished" datetime="2022-03-20T11:03:00+08:00">2022-03-20</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2022-03-22 13:03:00" itemprop="dateModified" datetime="2022-03-22T13:03:00+08:00">2022-03-22</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/CV/" itemprop="url" rel="index"><span itemprop="name">CV</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="Inception"><a href="#Inception" class="headerlink" title="Inception"></a>Inception</h1><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>一般来说，提升神经网络性能最直接的办法就是增加网络的尺寸，包括增加网络的深度和宽度两个方面。但这种方式存在一些问题：</p>
<ol>
<li><p>参数太多，如果训练数据集有限，很容易产生过拟合；</p>
</li>
<li><p>网络越大，参数越多，计算复杂度越高，难以应用；</p>
</li>
<li><p>网络越深，容易出现梯度弥散问题，难以优化模型；</p>
</li>
</ol>
<h2 id="Inception-v1"><a href="#Inception-v1" class="headerlink" title="Inception-v1"></a>Inception-v1</h2><p>深度研究 Inception Net模型之前，必须了解 Inception 网络的一个重要概念：</p>
<p><strong>1×1卷积</strong>：1×1 卷积简单地将输入像素及其所有相应通道映射到输出像素。1×1卷积作为降维模块，一定程度上减少的计算量。</p>
<ul>
<li>例如，在不使用1×1卷积的情况下执行5×5卷积，如下所示：</li>
</ul>
<p><img title="" src="https://vino-1316924433.cos.ap-beijing.myqcloud.com/inceptionNet.png" alt="" data-align="center"></p>
<p>FLOPs运算次数：（14×14×48）×（5×5×480）= 112.9M</p>
<ul>
<li>使用 1×1 卷积：</li>
</ul>
<p><img src="https://vino-1316924433.cos.ap-beijing.myqcloud.com/inceptionNet2.png" title="" alt="" data-align="center"></p>
<p>FLOPs运算次数</p>
<p>1×1卷积的操作数= （14×14×16）×（1×1×480）=1.5M<br>5×5卷积的操作数= （14×14×48）×（5×5×16 ) = 3.8M<br>相加后，1.5M + 3.8M = 5.3M</p>
<p>因此1×1卷积可以帮助减少模型大小，这可以在某种程度上帮助减少过度拟合问题；</p>
<p><strong>降维初始模型</strong></p>
<p><img src="https://vino-1316924433.cos.ap-beijing.myqcloud.com/modified.png" title="" alt="" data-align="center"></p>
<h2 id="Inception-v2"><a href="#Inception-v2" class="headerlink" title="Inception v2"></a>Inception v2</h2><h3 id="Inception-v1架构的问题"><a href="#Inception-v1架构的问题" class="headerlink" title="Inception v1架构的问题"></a>Inception v1架构的问题</h3><p>Inception V1有时会使用5×5等卷积，导致输入维度大幅下降。这导致神经网络使用一些精度下降。其背后的原因是，如果输入维度下降得太快，神经网络容易丢失信息。 此外，与3×3相比，<br>当我们使用更大的卷积（如5×5 ）时，复杂度也会降低. 我们可以在因式分解方面走得更远，即我们可以将3×3卷积分成<strong>1×3</strong>的非对称卷积，然后是3×1卷积。这相当于滑动一个具有与3×3卷积相同感受野但比*3×3便宜33%的两层网络。当输入维度很大但仅当输入大小为mxm时，这种分解不适用于早期层（m 在 12 到 20 之间）。根据 Inception V1 架构，辅助分类器提高了网络的收敛性。他们认为，通过将有用的梯度推到较早的层（以减少损失），它可以帮助减少深层网络中梯度消失问题的影响。但是，这篇论文的作者发现这个分类器在训练的早期并没有很好地提高收敛性。</p>
<h3 id="Batch-Normalization"><a href="#Batch-Normalization" class="headerlink" title="Batch Normalization"></a>Batch Normalization</h3><p>在BN的论文里，作者提出了Internal Covariate Shift这个问题，即在训练神经网络的过程中，因为前一层的参数变化而导致每层的输入分布都在不断变化（the distribution of each layer’s inputs changes during training, as the parameters of the previous layers change）。这使得我们需要更低的学习率和更小心地进行参数初始化，导致我们难以充分构建一个具有饱满地非线性结构的模型，而这个现象就被称作Internal Covariate Shift。为了解决这个问题，Google提出了Batch Normalization（批规范化）。即在每次梯度下降前，对每个mini-batch做归一化操作来降低数据分布的影响。</p>
<h3 id="小卷积和代替大卷积核"><a href="#小卷积和代替大卷积核" class="headerlink" title="小卷积和代替大卷积核"></a>小卷积和代替大卷积核</h3><p><img title="" src="https://vino-1316924433.cos.ap-beijing.myqcloud.com/5x5replaced3x3.png" alt="灯箱" data-align="center"></p>
<p>该架构还将 nXn 分解转换为<em>1xn</em>和 nx1 分解。正如我们上面讨论的，3×3 卷积可以转换为<em>1×3 ，然后是 3×1 卷积，与<em>*3×3</em></em>相比，计算复杂度降低了 33% 。</p>
<p><img title="" src="https://vino-1316924433.cos.ap-beijing.myqcloud.com/1xn.png" alt="灯箱" data-align="center"></p>
<h2 id="Inception-v3"><a href="#Inception-v3" class="headerlink" title="Inception v3"></a>Inception v3</h2><p>Inception v3 类似于 Inception v2，并做了以下改动：</p>
<ul>
<li><p>使用 RMSprop 优化器；</p>
</li>
<li><p>辅助分类器全连接层的BN；</p>
</li>
<li><p>使用 7×7 分解卷积；</p>
</li>
</ul>
<h2 id="Inception-v4"><a href="#Inception-v4" class="headerlink" title="Inception v4"></a>Inception v4</h2><p>将 Inception 模块和残差连接 结合起来。</p>
<p><img src="https://vino-1316924433.cos.ap-beijing.myqcloud.com/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA57qi6bKk6bG85LiO57u_6am0,size_20,color_FFFFFF,t_70,g_se,x_16.png" alt=""></p>
<p>EmbOding!9196#CN360</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




  <nav class="pagination">
    <a class="extend prev" rel="prev" title="Previous page" aria-label="Previous page" href="/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="page-number current">2</span>
  </nav>

</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2024</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">Jie Chu</span>
  </div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/muse/" rel="noopener" target="_blank">NexT.Muse</a>
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script>

  






  




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>



</body>
</html>
