<!DOCTYPE html>
<html lang="zh">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="google-site-verification" content="BTo06tdvlac_Dho4-PFTLmDqjKXr1KtOzavpD8XDA5k" />
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 7.0.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.0/css/all.min.css" integrity="sha256-yIDrPSXHZdOZhAqiBP7CKzIwMQmRCJ8UeB8Jo17YC4o=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"example.com","root":"/","images":"/images","scheme":"Muse","darkmode":false,"version":"8.19.1","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"}}</script><script src="/js/config.js"></script>

    <meta name="description" content="日常笔记">
<meta property="og:type" content="website">
<meta property="og:title" content="CJ blog">
<meta property="og:url" content="http://example.com/index.html">
<meta property="og:site_name" content="CJ blog">
<meta property="og:description" content="日常笔记">
<meta property="og:locale">
<meta property="article:author" content="Jie Chu">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="http://example.com/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":true,"isPost":false,"lang":"zh","comments":"","permalink":"","path":"index.html","title":""}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>CJ blog</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">CJ blog</h1>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">不知名算法工程师</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="Search" role="button">
    </div>
  </div>
</div>







</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Jie Chu</p>
  <div class="site-description" itemprop="description">日常笔记</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">10</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">2</span>
        <span class="site-state-item-name">tags</span>
      </div>
  </nav>
</div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/12/20/hello-world/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Jie Chu">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="CJ blog">
      <meta itemprop="description" content="日常笔记">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | CJ blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/12/20/hello-world/" class="post-title-link" itemprop="url">Hello World</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2023-12-20 00:09:14" itemprop="dateCreated datePublished" datetime="2023-12-20T00:09:14+08:00">2023-12-20</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>Welcome to <a target="_blank" rel="noopener" href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a target="_blank" rel="noopener" href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a target="_blank" rel="noopener" href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a target="_blank" rel="noopener" href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>
<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/writing.html">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>
<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>
<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>
<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/04/21/EVA02/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Jie Chu">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="CJ blog">
      <meta itemprop="description" content="日常笔记">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | CJ blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/04/21/EVA02/" class="post-title-link" itemprop="url">EVA02解析</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2023-04-21 21:03:00" itemprop="dateCreated datePublished" datetime="2023-04-21T21:03:00+08:00">2023-04-21</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2023-04-22 23:03:00" itemprop="dateModified" datetime="2023-04-22T23:03:00+08:00">2023-04-22</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="EVA-02-A-Visual-Representation-for-Neon-Genesis"><a href="#EVA-02-A-Visual-Representation-for-Neon-Genesis" class="headerlink" title="EVA-02: A Visual Representation for Neon Genesis"></a>EVA-02: A Visual Representation for Neon Genesis</h1><p>EVA02的目标是作为下一代的基于Transformer的视觉表示模型。</p>
<p>文章主要包含两个部分：1、对普通Vit的架构改进，2、MIM的预训练策略</p>
<p><strong>总结</strong></p>
<p>EVA02主要有两个改进，一是，通过实验的方法来观察采用哪些NLP方向关于Vit的改进；二是，增加视觉特征编码的容量以及增加训练的轮数和图像的size；</p>
<h2 id="1-Architecture"><a href="#1-Architecture" class="headerlink" title="1 Architecture"></a>1 Architecture</h2><p><img src="https://vino-1316924433.cos.ap-beijing.myqcloud.com/image-20230629182751431.png" alt="image-20230629182751431"></p>
<p>ViT主要由 MHSA（用于全局空间信息聚合）和 pointwise的FFNs（特征变换）交错组成。但是NLP方面很多针对ViT的修改没有在视觉上应用。作者做了一个实验来探索不同的修改带来的影响：</p>
<p><img src="https://vino-1316924433.cos.ap-beijing.myqcloud.com/image-20230703191529244.png" alt="image-20230703191529244"></p>
<p><strong>Gelu</strong>: $GELU(x)=x * \phi(x),x \sim N(0,1)$</p>
<p><img src="https://vino-1316924433.cos.ap-beijing.myqcloud.com/v2-0d8b979444f64ab49d4bc0f4199a15c2_r.jpg" alt="img"></p>
<p><img src="https://vino-1316924433.cos.ap-beijing.myqcloud.com/%E6%88%AA%E5%9B%BE20230914183157.png" alt="截图20230914183157"></p>
<p><img src="https://vino-1316924433.cos.ap-beijing.myqcloud.com/v2-e31b1e5b4333a90fbcca03c9a863a0c5_r.jpg" alt="img"></p>
<h2 id="2-pre-trainning-strategy"><a href="#2-pre-trainning-strategy" class="headerlink" title="2 pre-trainning strategy"></a>2 pre-trainning strategy</h2><p><img src="https://vino-1316924433.cos.ap-beijing.myqcloud.com/image-20230703195140612.png" alt="image-20230703195140612"></p>
<p><strong>MIM teacher model变大，训练的epoch也需要变多；</strong></p>
<p><img src="https://vino-1316924433.cos.ap-beijing.myqcloud.com/image-20230703195449659.png" alt="image-20230703195449659"></p>
<p><strong>分辨率的增加以及在imgnet数据上的有监督ft也会增加性能</strong></p>
<p>预训练目标类似于 EVA [44]，即仅以可见图像块为条件回归屏蔽图像文本对齐的视觉特征。我们使用 [MASK] 标记破坏输入补丁，并按照 [5, 44] 使用掩码率为 40% 的分块掩码。</p>
<p>MIM 预训练的目标表示来自可公开访问的 EVA-CLIP [44] 视觉塔，具有 10 亿个参数。 EV A-02 的输出特征首先被归一化 [4]，然后通过线性层投影到与 EVA-CLIP 的视觉特征相同的维度。我们使用负余弦相似度作为损失函数。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/03/21/EMA/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Jie Chu">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="CJ blog">
      <meta itemprop="description" content="日常笔记">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | CJ blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/03/21/EMA/" class="post-title-link" itemprop="url">EMA原理和pytorch实现</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2023-03-21 21:03:00" itemprop="dateCreated datePublished" datetime="2023-03-21T21:03:00+08:00">2023-03-21</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2023-03-22 23:03:00" itemprop="dateModified" datetime="2023-03-22T23:03:00+08:00">2023-03-22</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="EMA的原理和pytorch实现"><a href="#EMA的原理和pytorch实现" class="headerlink" title="EMA的原理和pytorch实现"></a>EMA的原理和pytorch实现</h1><h2 id="EMA-定义"><a href="#EMA-定义" class="headerlink" title="EMA 定义"></a>EMA 定义</h2><p>指数移动平均也叫权重移动平均，是一种给予近期数据更高权重的平均方法。</p>
<h2 id="在深度学习的优化中的EMA"><a href="#在深度学习的优化中的EMA" class="headerlink" title="在深度学习的优化中的EMA"></a>在深度学习的优化中的EMA</h2><p>在深度学习的优化过程中，$\theta_t$ 是 t 时刻的模型权重 weight， $\upsilon_t$ 是 t 时刻的影子权重。在梯度下降的过程中，会一直维护着这个影子权重，但是这个影子权重不会参与训练。基本的假设是<strong>模型权重在最后 n 步内，会在实际的最优点处抖动，所以我们去最后 n 步的平均，能使模型更加的鲁棒。</strong></p>
<h3 id="EMA为何有效"><a href="#EMA为何有效" class="headerlink" title="EMA为何有效"></a>EMA为何有效</h3><p>因为在训练的时候，会使用验证集来衡量模型精度，但是验证集和测试集并不完全一致，在训练后期阶段，模型可能已经在测试集最佳精度附近波动，所以使用ema的结果会比使用单一结果更可靠。</p>
<p><img src="https://vino-1316924433.cos.ap-beijing.myqcloud.com/image-20230307191607861.png" alt="image-20230307191607861"></p>
<p><img src="https://vino-1316924433.cos.ap-beijing.myqcloud.com/image-20230307191620727.png" alt="image-20230307191620727"></p>
<h3 id="Pytorch实现"><a href="#Pytorch实现" class="headerlink" title="Pytorch实现"></a>Pytorch实现</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">EMA</span>():</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, model, decay</span>):</span><br><span class="line">        self.model = model</span><br><span class="line">        self.decay = decay</span><br><span class="line">        self.shadow = &#123;&#125;</span><br><span class="line">        self.backup = &#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">register</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">for</span> name, param <span class="keyword">in</span> self.model.named_parameters():</span><br><span class="line">            <span class="keyword">if</span> param.requires_grad:</span><br><span class="line">                self.shadow[name] = param.data.clone()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">update</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">for</span> name, param <span class="keyword">in</span> self.model.named_parameters():</span><br><span class="line">            <span class="keyword">if</span> param.requires_grad:</span><br><span class="line">                <span class="keyword">assert</span> name <span class="keyword">in</span> self.shadow</span><br><span class="line">                new_average = (<span class="number">1.0</span> - self.decay) * param.data + self.decay * self.shadow[name]</span><br><span class="line">                self.shadow[name] = new_average.clone()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">apply_shadow</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">for</span> name, param <span class="keyword">in</span> self.model.named_parameters():</span><br><span class="line">            <span class="keyword">if</span> param.requires_grad:</span><br><span class="line">                <span class="keyword">assert</span> name <span class="keyword">in</span> self.shadow</span><br><span class="line">                self.backup[name] = param.data</span><br><span class="line">                param.data = self.shadow[name]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">restore</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">for</span> name, param <span class="keyword">in</span> self.model.named_parameters():</span><br><span class="line">            <span class="keyword">if</span> param.requires_grad:</span><br><span class="line">                <span class="keyword">assert</span> name <span class="keyword">in</span> self.backup</span><br><span class="line">                param.data = self.backup[name]</span><br><span class="line">        self.backup = &#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化</span></span><br><span class="line">ema = EMA(model, <span class="number">0.999</span>)</span><br><span class="line">ema.register()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练过程中，更新完参数后，同步update shadow weights</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>():</span><br><span class="line">    optimizer.step()</span><br><span class="line">    ema.update()</span><br><span class="line"></span><br><span class="line"><span class="comment"># eval前，apply shadow weights；eval之后，恢复原来模型的参数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">evaluate</span>():</span><br><span class="line">    ema.apply_shadow()</span><br><span class="line">    <span class="comment"># evaluate</span></span><br><span class="line">    ema.restore()</span><br></pre></td></tr></table></figure>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/02/24/lora/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Jie Chu">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="CJ blog">
      <meta itemprop="description" content="日常笔记">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | CJ blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/02/24/lora/" class="post-title-link" itemprop="url">Lora</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>
      

      <time title="Created: 2023-02-24 23:00:00 / Modified: 23:53:00" itemprop="dateCreated datePublished" datetime="2023-02-24T23:00:00+08:00">2023-02-24</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="LoRA"><a href="#LoRA" class="headerlink" title="LoRA"></a>LoRA</h1><p>论文链接：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2106.09685">https://arxiv.org/abs/2106.09685</a><br>代码链接：<a target="_blank" rel="noopener" href="https://github.com/microsoft/LoRA">https://github.com/microsoft/LoRA</a></p>
<p>LoRA是一种finetune扩散模型的训练技术。通过对标准的checkpoint模型微小的修改，可以比checkpoint模型小10到100倍。LoRA的原理比较简单，原始全量的finetune其实就是在原始模型参数基础上加入增量$W=W_0+\Delta W$，那么我们可以通过冻结原始参数 $W_0$，并且把增量部分通过低秩分解方式进一步降低参数量级$\Delta W = A*B^T$, 原始参数的维度是 $d*d$, 则低秩分解后的参数量级是 $2*r*d$, 这里 $r&lt;&lt;d$， 因此可以起到大幅降低微调参数量级的效果。</p>
<p>和textula inversion一样，不能直接使用LoRA模型，需要和checkpoint文件一起使用。</p>
<h2 id="How-does-LoRA-work-in-Stable-diffusion？"><a href="#How-does-LoRA-work-in-Stable-diffusion？" class="headerlink" title="How does LoRA work in Stable diffusion？"></a>How does LoRA work in Stable diffusion？</h2><p><img src="https://vino-1316924433.cos.ap-beijing.myqcloud.com/45f7e2ce00c48b8c96e938c9fe8ed3d4.png" alt="image"></p>
<p>LoRA通过在checkpoint上做小的修改替换风格，具体而言修改的地方是UNet中的cross-attention层。该层是图像和文本prompt交界的层。LORA的作者们发现微调该部分足以实现良好的性能。</p>
<p>cross attention层的权重是一个矩阵，LoRA fine tune这些权重来微调模型。那么LoRA是怎么做到模型文件如此小？LoRA的做法是将一个权重矩阵分解为两个矩阵存储，能起到的作用可以用下图表示，参数量由(1000<em> 2000)减少到(1000</em> 2+2000*2), 大概300多倍！</p>
<p><img src="https://vino-1316924433.cos.ap-beijing.myqcloud.com/10bbf49b2e9042779941c600a692d74dtplv-k3u1fbpfcp-zoom-in-crop-mark1512000.webp" alt="img"></p>
<p><strong>核心代码</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## 初始化低秩矩阵A和B</span></span><br><span class="line">self.lora_A.update(nn.ModuleDict(&#123;adapter_name: nn.Linear(self.in_features, r, bias=<span class="literal">False</span>)&#125;))</span><br><span class="line">self.lora_B.update(nn.ModuleDict(&#123;adapter_name: nn.Linear(r, self.out_features, bias=<span class="literal">False</span>)&#125;))</span><br><span class="line">self.scaling[adapter_name] = lora_alpha / r</span><br><span class="line"></span><br><span class="line"><span class="comment">## 向前计算</span></span><br><span class="line">result = F.linear(x, transpose(self.weight, self.fan_in_fan_out), bias=self.bias)</span><br><span class="line">result += (</span><br><span class="line">    self.lora_B[self.active_adapter](</span><br><span class="line">        self.lora_A[self.active_adapter](self.lora_dropout[self.active_adapter](x))</span><br><span class="line">    )</span><br><span class="line">    * self.scaling[self.active_adapter]</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>alpha参数：alpha其实是个缩放参数，本质和learning rate相同。</p>
<h2 id="cross-attention"><a href="#cross-attention" class="headerlink" title="cross attention"></a>cross attention</h2><p>cross-attention是扩散模型中关键的技术之一，在LoRA中通过微调该模块，即可微调生成图片的样式，而在Hypernetwork中使用两个带有dropout和激活函数的全链接层，分别修改cross attention中的key和value，也可以定制想要的生成风格。可见cross attention的重要性。</p>
<p>在讲cross-attention之前，先看看经典的transformer中attention的含义，attnetion实际上用了三个QKV矩阵，来计算不同token之间的彼此的依赖关系，Q和K可以用来计算当前token和其他token的相似度，这个相似度作为权值对V进行加权求和，可以作为下一层的token。更通俗点说，Q和k的作用是用来在token之间搬运信息，而value本身就是从当前token当中提取出来的信息. 比较常见的是self-attention，该注意力是一个sequence内部不同token间产生注意力，而cross-attention的区别是在不同的sequence之间产生注意力。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/01/21/dali%E9%A2%84%E5%A4%84%E7%90%86/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Jie Chu">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="CJ blog">
      <meta itemprop="description" content="日常笔记">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | CJ blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/01/21/dali%E9%A2%84%E5%A4%84%E7%90%86/" class="post-title-link" itemprop="url">DALI加速图像数据预处理</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2023-01-21 23:03:00" itemprop="dateCreated datePublished" datetime="2023-01-21T23:03:00+08:00">2023-01-21</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="DALI预处理加速"><a href="#DALI预处理加速" class="headerlink" title="DALI预处理加速"></a>DALI预处理加速</h1><p>NVIDIA DALI 文档：<a target="_blank" rel="noopener" href="https://docs.nvidia.com/deeplearning/dali/user-guide/docs/examples/general/data_loading/external_input.html">https://docs.nvidia.com/deeplearning/dali/user-guide/docs/examples/general/data_loading/external_input.html</a></p>
<p>安装：<a target="_blank" rel="noopener" href="https://docs.nvidia.com/deeplearning/dali/user-guide/docs/installation.html#pip-official-releases">https://docs.nvidia.com/deeplearning/dali/user-guide/docs/installation.html#pip-official-releases</a></p>
<h2 id="1、DALI-pipeline"><a href="#1、DALI-pipeline" class="headerlink" title="1、DALI pipeline"></a>1、DALI pipeline</h2><p>DALI可以选择纯CPU加载和预处理或者CPU&amp;GPU混合加载，GPU加载。</p>
<p>在DALI中，任何数据处理任务都有一个称为 Pipeline 的对象， Pipeline 对象是类的实例<a target="_blank" rel="noopener" href="https://docs.nvidia.com/deeplearning/dali/user-guide/docs/pipeline.html#nvidia.dali.Pipeline"><code>nvidia.dali.Pipeline</code></a>或派生类。</p>
<p>可以通过以下方式定义DALI Pipeline</p>
<ol>
<li>通过实现内部使用 DALI 运算符的函数并使用<a target="_blank" rel="noopener" href="https://docs.nvidia.com/deeplearning/dali/user-guide/docs/pipeline.html#nvidia.dali.pipeline_def"><code>pipeline_def()</code></a>装饰器对其进行装饰。</li>
<li>通过<a target="_blank" rel="noopener" href="https://docs.nvidia.com/deeplearning/dali/user-guide/docs/pipeline.html#nvidia.dali.Pipeline"><code>Pipeline</code></a>直接实例化对象、构建图形并使用<a target="_blank" rel="noopener" href="https://docs.nvidia.com/deeplearning/dali/user-guide/docs/pipeline.html#nvidia.dali.Pipeline.set_outputs"><code>Pipeline.set_outputs()</code></a>.</li>
<li>通过从<a target="_blank" rel="noopener" href="https://docs.nvidia.com/deeplearning/dali/user-guide/docs/pipeline.html#nvidia.dali.Pipeline"><code>Pipeline</code></a>类继承并覆盖<a target="_blank" rel="noopener" href="https://docs.nvidia.com/deeplearning/dali/user-guide/docs/pipeline.html#nvidia.dali.Pipeline.define_graph"><code>Pipeline.define_graph()</code></a>（这是定义 DALI Pipelines 的传统方式）</li>
</ol>
<p><img src="https://vino-1316924433.cos.ap-beijing.myqcloud.com/%E6%88%AA%E5%9B%BE20230907195707.png" alt="截图20230907195707"></p>
<h2 id="2、图像分类的pipeline示例"><a href="#2、图像分类的pipeline示例" class="headerlink" title="2、图像分类的pipeline示例"></a>2、图像分类的pipeline示例</h2><p>所有操作均在GPU上，note：<strong>使用gpu进行预处理，会占用显存，模型越大占用越多，但是GPU利用率会一直保持在100%</strong>。模型较大不推荐使用GPU加载。</p>
<p><strong>使用纯CPU操作，数据处理的速度也比 torchvision快</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">TrainPipeline</span>(<span class="title class_ inherited__">Pipeline</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, batch_size, num_threads, device_id, data_root, img_size, n_holes, length, custom_cutout=<span class="literal">False</span></span>):</span><br><span class="line">         </span><br><span class="line">        <span class="built_in">super</span>(TrainPipeline, self).__init__(batch_size, num_threads, device_id, prefetch_queue_depth=<span class="number">4</span>)</span><br><span class="line">        mode = <span class="string">&#x27;gpu&#x27;</span></span><br><span class="line">        self.decode = ops.decoders.Image(device=<span class="string">&#x27;mixed&#x27;</span>)</span><br><span class="line"> </span><br><span class="line">        self.img_size = img_size</span><br><span class="line"> </span><br><span class="line">        <span class="comment"># readers.File类似torchvision.datasets.ImageFolder，dali还有其他高阶API，可自行研究使用</span></span><br><span class="line">        self.<span class="built_in">input</span> = ops.readers.File(file_root=data_root, random_shuffle=<span class="literal">True</span>)</span><br><span class="line">        <span class="comment"># Resize</span></span><br><span class="line">        self.resize = ops.Resize(device=mode, resize_x=<span class="built_in">int</span>(img_size*<span class="number">1.2</span>), resize_y=<span class="built_in">int</span>(img_size*<span class="number">1.2</span>))</span><br><span class="line">        <span class="comment"># Randomcrop，类似于torchvision.transforms.RandomCrop</span></span><br><span class="line">        self.randomcrop = ops.RandomResizedCrop(device=mode, size=img_size, random_area=[<span class="number">0.3</span>, <span class="number">1.0</span>])</span><br><span class="line">        <span class="comment"># CropMirrorNormalize可以实现normalize和随机水平翻转，类似于torchvision.transforms.Normalize &amp; RandomHorizontalFlip</span></span><br><span class="line">        self.normalize = ops.CropMirrorNormalize(device=mode, mean=[<span class="number">0.5</span>*<span class="number">255</span>, <span class="number">0.5</span>*<span class="number">255</span>, <span class="number">0.5</span>*<span class="number">255</span>],</span><br><span class="line">                                                 std=[<span class="number">0.5</span>*<span class="number">255</span>, <span class="number">0.5</span>*<span class="number">255</span>, <span class="number">0.5</span>*<span class="number">255</span>])</span><br><span class="line">        <span class="comment"># 获取随机数</span></span><br><span class="line">        self.rng1 = ops.random.Uniform()</span><br><span class="line">        self.rng2 = ops.random.CoinFlip()</span><br><span class="line">        <span class="comment"># 实例化改变图片色彩的类，类似于torchvision.transforms.ColorJitter</span></span><br><span class="line">        self.colortwist = ops.ColorTwist(device=mode)</span><br><span class="line">        <span class="comment"># 实例化旋转图像的类，类似于torchvision.transforms.RandomRotation</span></span><br><span class="line">        self.rotate = ops.Rotate(device=mode, fill_value=<span class="number">0</span>)</span><br><span class="line">        <span class="comment"># gridmask，类似于cutout这种随机遮挡块操作</span></span><br><span class="line">        self.gridmask = ops.GridMask(device=mode)</span><br><span class="line">       </span><br></pre></td></tr></table></figure>
<p>如果需要自定义数据处理的函数，可参考一下方式。以cutout为例：cutout使用的是cpu处理了，如果是gpu处理的话，<strong>需要将numpy改成cupy，DALI原生支持的操作和数据增强挺丰富的。</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">CUTOUT</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, n_holes, length</span>):</span><br><span class="line">        self.n_holes = n_holes</span><br><span class="line">        self.length = length</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__call__</span>(<span class="params">self, imgs</span>):</span><br><span class="line">        c, h, w = imgs.shape</span><br><span class="line">        mask = np.ones((h, w), np.float32)</span><br><span class="line">        <span class="keyword">for</span> n <span class="keyword">in</span> <span class="built_in">range</span>(self.n_holes):</span><br><span class="line">            y = np.random.randint(h)</span><br><span class="line">            x = np.random.randint(w)</span><br><span class="line">            y1 = np.clip(y - self.length // <span class="number">2</span>, <span class="number">0</span>, h)</span><br><span class="line">            y2 = np.clip(y + self.length // <span class="number">2</span>, <span class="number">0</span>, h)</span><br><span class="line">            x1 = np.clip(x - self.length // <span class="number">2</span>, <span class="number">0</span>, w)</span><br><span class="line">            x2 = np.clip(x + self.length // <span class="number">2</span>, <span class="number">0</span>, w)</span><br><span class="line">            mask[y1: y2, x1: x2] = <span class="number">0.</span></span><br><span class="line">        mask = np.expand_dims(mask, <span class="number">0</span>).repeat(c, axis=<span class="number">0</span>)</span><br><span class="line">        imgs = imgs * mask</span><br><span class="line"> </span><br><span class="line">        <span class="keyword">return</span> imgs</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 然后在上面的 TrainPipeline上加上下面这行,model 是 “cpu”</span></span><br><span class="line">    self.mask = ops.PythonFunction(device=<span class="string">&quot;cpu&quot;</span>, function=CUTOUT(n_holes, length), num_outputs=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<p>图像分类数据加载的时候的调用方式：其他的Iterator可以参考 <a target="_blank" rel="noopener" href="https://docs.nvidia.com/deeplearning/dali/user-guide/docs/plugins/pytorch_tutorials.html">https://docs.nvidia.com/deeplearning/dali/user-guide/docs/plugins/pytorch_tutorials.html</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> nvidia.dali.plugin.pytorch <span class="keyword">import</span> DALIClassificationIterator</span><br><span class="line"><span class="keyword">from</span> nvidia.dali.plugin.base_iterator <span class="keyword">import</span> LastBatchPolicy</span><br><span class="line"> </span><br><span class="line">pipe_train = TrainPipeline(batch_size, num_threads, device_id, data_root, img_size, n_holes, length,custom_cutout=custom_cutout)</span><br><span class="line">pipe_train.build()</span><br><span class="line">         </span><br><span class="line"><span class="comment"># DALIClassificationIterator: 返回pytorch tensor 形式是 (data and label) , 即DataLoader</span></span><br><span class="line">train_loader = DALIClassificationIterator(pipe_train, size=pipe_train.epoch_size(<span class="string">&#x27;Reader&#x27;</span>),last_batch_policy=LastBatchPolicy.PARTIAL, auto_reset=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2022/06/21/DARN/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Jie Chu">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="CJ blog">
      <meta itemprop="description" content="日常笔记">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | CJ blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/06/21/DARN/" class="post-title-link" itemprop="url">图片美观度模型</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2022-06-21 21:00:00" itemprop="dateCreated datePublished" datetime="2022-06-21T21:00:00+08:00">2022-06-21</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2022-06-22 23:08:00" itemprop="dateModified" datetime="2022-06-22T23:08:00+08:00">2022-06-22</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="360图片搜索—图片美观度模型"><a href="#360图片搜索—图片美观度模型" class="headerlink" title="360图片搜索—图片美观度模型"></a>360图片搜索—图片美观度模型</h1><p><a target="_blank" rel="noopener" href="https://github.com/lmm360/Image-aesthetic-assessment">code和数据集地址</a></p>
<h2 id="一、背景"><a href="#一、背景" class="headerlink" title="一、背景"></a>一、背景</h2><p>在图片搜索中，用户希望搜索的图片不但和自己的查询相关，并且在视觉感官、图片质量等方面也要比较满意。此时，就需要我们计算图片图片的在美学上的特征分值，加到排序模型中，将高相关性、高美学质量的图像排在检索结果的前面。</p>
<p>但是现有的图片质量模型主要考虑图像的质量，如像素，清晰度、有无噪声，在图像的美学特征，如构图、色彩、内容和谐等考虑的权重偏低。</p>
<h2 id="二、相关研究"><a href="#二、相关研究" class="headerlink" title="二、相关研究"></a>二、相关研究</h2><p>大部分的工作将这种美观度评估的任务形式化为回归或者分类问题。开源的数据集有 AVA【1】, AADB【2】等。代表的工作有 NIMA模型【3】和DARN模型【4】。360美观度模型正是在DARN模型的基础上改进得到的。</p>
<p><strong>NIMA模型</strong>利用了AVA数据集，AVA数据集包含了约 25w张图像，由业余摄影师根据审美品质进行评分，200人评分的平均分就是该张图像的最终的分数。</p>
<p><strong>NIMA模型</strong>目标是预测与人类评分的相关性，而不是将图片分类或者回归到平均分。提出了<strong>EMD loss</strong>，它显示了有序类分类的性能提升。下面是模型结构。</p>
<p><img src="https://vino-1316924433.cos.ap-beijing.myqcloud.com/image-20231026144748579.png" alt="image-20231026144748579"></p>
<p>开源的数据集AVA、AADB图像与图片搜索的图像在种类和美学质量分布上有很大的差异，所以不能再公开的数据集上训练模型。最好的方式使构建自己的数据集，但是像AVA数据集的构建，需要一批具有美学专业知识的标注人员对每张图片进行标注。标注成本和难度都有很大</p>
<p>Microsoft提出了<a href="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1805.00309">《An Universal Image Attractiveness Ranking Framework》</a>，很好的解决美学数据集构建难的问题，并提出了新的美学模型——DARN模型。下面介绍DARN模型以及360美观度模型在此之上的改进。</p>
<h2 id="三、基于DARN的美观度模型"><a href="#三、基于DARN的美观度模型" class="headerlink" title="三、基于DARN的美观度模型"></a>三、基于DARN的美观度模型</h2><h3 id="1、数据集构建"><a href="#1、数据集构建" class="headerlink" title="1、数据集构建"></a>1、数据集构建</h3><p>数据集的构建过程如下：</p>
<p>1、在图片搜索中高中低频queey中各选择2000条query。</p>
<p>2、根据query在图片搜索返回结果中，top20里面，top40-60里面各抽取两张图片。</p>
<p>3、根据Swiss-system tournament规则、对这4张图像进行三轮标注。</p>
<p>4、每一轮标注，将同一query下4张图片组成两对，每一对图像由7个人标注人员去进行投票：</p>
<p>左边更好，左边好一点，一样好，右边好一点，右边更好。</p>
<p>具体标注可以参考下图：</p>
<p><img src="https://vino-1316924433.cos.ap-beijing.myqcloud.com/image-20231026154542693.png" alt="image-20231026154542693"></p>
<p>这样标注的好处是，标注人员无需掌握专业知识，“比较”相对于给出一个直接的分值更简单，多人投票也降低主观偏好带来的偏差。7个标注人员对image1和image2进行投票的结果中，左边更好，左边好一点，一样好，右边好一点，右边更好的人数分别为0、1、1、4、1，则这对图像的label为：</p>
<script type="math/tex; mode=display">
l(image1,image2)=(0,1,1,4,1)</script><h3 id="2、DARN模型"><a href="#2、DARN模型" class="headerlink" title="2、DARN模型"></a>2、DARN模型</h3><p>我们的标注数据是pair对，模型结构如下：</p>
<p><img src="https://vino-1316924433.cos.ap-beijing.myqcloud.com/image-20231026163835872.png" alt="image-20231026163835872"></p>
<p>左边的网络和右边的网络是参数共享的，图像对输入到网络中，经过 Deep CNN（如resnet50）的特征抽取，再经过三个fc层，然后计算最终输出的方差和均值。</p>
<p>假设每张图像都是由很多的专业的美学专家评分得到的，那么根据中心极限定理，图像美观度分值$X$服从正态分布，AVA数据基本就符合正态分布。所以<strong>最终计算得到的均值和方差就可以看作是模型计算的该图像的平均美观度分值和方差</strong>。</p>
<p>对于一个pair对 $[x_i,x_j]$, 它们的 label 记为${0,1,2,3,4}$ 分别对应着左边更好，左边好一点，一样好，右边好一点，右边更好。对于我们的标注数据有：</p>
<script type="math/tex; mode=display">
\sum_{y=0}^4{P_{ij}(xi-xj)=y}=1</script><p>直觉上，图像通过模型得到的美观度分值有以下两个特点：</p>
<ul>
<li>图像越美观，模型得到美观度分数均值越大。</li>
<li>图像对的label应该与美观度分数一致。如，$u_i&gt;&gt;u_j$,那么标注图像 $i$ 好一点或者更好的人数应该更多。如果 $u_i=u_j$,则大部分人标注的 label 是 “一样好”。</li>
</ul>
<p>上面说到我们假设美观度分值服从正态分布，那么两个美观度分值的差也服从正态分布，记$x_{i}^{left}$,$x_{j}^{right}$分别表示图像对中左边图像美观度和右边图像美观度（左边和右边只是为了对应我们数据的标注label），他们美观度的差值 $\Delta X$ 服从 $N(x,u_i-u_j,\sigma_{1}^{2}+\sigma_{2}^{2})$。</p>
<p>然后我们定义4个可以学习的边界值 ${b_i}_{i=0}^{3}$，这4个boundaries将 x 轴分成5部分，也就将正态分布和x轴围成的区域分成了5个部分，这5个部分就对应了 我们设定的 五个label {左边更好，左边好一点，一样好，右边好一点，右边更好}，我们定义 $p_{i}^{j}，j={0,1,2,3}$表示第$i$对图像对被标注lable $j$ 的概率。$\Delta u_i $和 $\Delta \sigma_i$ 表示第$i$对图像对美观度分值差的均值和方差。于是我们有：</p>
<script type="math/tex; mode=display">
p_{i}^{j}=\displaystyle \int^{b_j}_{b_{j-1}}N(x;\Delta u_i,\Delta \sigma_i)dx</script><p>形象点可以看下图：</p>
<p><img src="https://vino-1316924433.cos.ap-beijing.myqcloud.com/image-20231026175218691.png" alt="image-20231026175218691"></p>
<p>上面这张图显示了标签如何随着图像对的分数差值系统的变化。当右侧图像的平均得分远高于左侧图像时，得分差的分布将向右移动，导致标签“右侧更好”的概率更高。当左右之间的分数差异变小时，分布向左移动并导致标签发生变化。因此，当两个图像的分数相等时，中间桶中的面积最大，这意味着这对图像最有可能被标记为“一样好”。</p>
<p>至此我们可以计算出模型对第 $i$ 对图像对的美观度分值的差的分布 $p_i=(p_{i}^{0},p_{i}^{1},p_{i}^{2},p_{i}^{3},p_{i}^{4})$ ，而我们</p>
<p>图像对的真实label 为 $l=(n_{i}^{0},n_{i}^{1},n_{i}^{2},n_{i}^{3},n_{i}^{4})$, 因此我们可以定义一个对数最大似然损失函数：</p>
<p><img src="https://vino-1316924433.cos.ap-beijing.myqcloud.com/image-20231026180559585.png" alt="image-20231026180559585"></p>
<p>从上面的过程可以看出，由于预先假设图像的美学评分服从正态分布，而正态分布可以由均值和方差两个参数控制，所以严格的说，DARN模型预测的不是美学评分，而是美学评分分布。<strong>在实际应用时，可以直接用均值作为该图像的美学评分</strong>。</p>
<h3 id="3、实验改进"><a href="#3、实验改进" class="headerlink" title="3、实验改进"></a>3、实验改进</h3><p>实验的过程中，根据我们的数据集和训练情况对DARN模型做了一些改进和调整。</p>
<p>1、 原始DARN模型中，deep CNN以及以后所有FC层，激活函数都是 Relu。缺少带有归一化能力的激活函数和norm操作，则很可能随着<a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=W方差&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra={&quot;sourceType&quot;%3A&quot;article&quot;%2C&quot;sourceId&quot;%3A&quot;83896463&quot;}">W方差</a>的增大，出现个别节点数值过大的问题，导致训练时loss很可能出现nan的情况。所以将第一个FC层的激活函数改为 tanh。</p>
<p>2、在计算均值之前加上softplus激活函数。使得最后推理的结果都是正的，且减小方差。模型中计算正态分布在某一个区间的积分，需要保证 $\sigma &gt;0$，才能让正态分布函数有意义，但是原始论文中：</p>
<p><img src="https://vino-1316924433.cos.ap-beijing.myqcloud.com/image-20231026182412236.png" alt="image-20231026182412236"></p>
<p>使用的是Relu激活函数，有可能训练得到 $\sigma = 0$。</p>
<p>3、训练中对边界值进行截断，防止训练中部分 $\Delta u$过大，产生nan值。</p>
<p>4、最后一层维度通过实验调整为 16。</p>
<p>5、边界值的初始化值对于模型训练影响很大，我们数据集下初始化值为（-0.75，-0.25， 0.25, 0.75）</p>
<p>6、deep CNN 由 resnet50 调整为 swin transformer。</p>
<h2 id="四、结果展示"><a href="#四、结果展示" class="headerlink" title="四、结果展示"></a>四、结果展示</h2><p><img src="https://vino-1316924433.cos.ap-beijing.myqcloud.com/image2022-11-3_15-17-31.png" alt="image2022-11-3_15-17-31"></p>
<p><img src="https://vino-1316924433.cos.ap-beijing.myqcloud.com/image2022-11-3_15-21-28.png" alt="image2022-11-3_15-21-28"></p>
<p><img src="https://vino-1316924433.cos.ap-beijing.myqcloud.com/image2022-11-3_15-24-26.png" alt="image2022-11-3_15-19-28"></p>
<p>该美观度模型计算的特征应用在360图片搜索的排序中，离线ndcg指标和在线Ctr均得到了提升。</p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>【1】N. Murray, L. Marchesotti, and F. Perronnin. Ava: A large-scale database for aesthetic visual analysis. In Computer Vision and Pattern Recognition (CVPR), pages 2408–2415,Providence, RI, USA, 2012. IEEE.</p>
<p>【2】S. Kong, X. Shen, Z. Lin, R. Mech, and C. Fowlkes. Photo aesthetics ranking network with attributes and content adapta-tion. In European Conference on Computer Vision (ECCV),<br>page 662679, Amsterdam, The Netherlands, 2016. Springer.</p>
<p>【3】H. Talebi and P . Milanfar. Nima: Neural image assess-ment. IEEE Transactions on Image Processing, 27:3998–4011, 2017</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2022/05/10/NIMA/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Jie Chu">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="CJ blog">
      <meta itemprop="description" content="日常笔记">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | CJ blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/05/10/NIMA/" class="post-title-link" itemprop="url">NIMA——Neural Image Assessment</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2022-05-10 21:00:00" itemprop="dateCreated datePublished" datetime="2022-05-10T21:00:00+08:00">2022-05-10</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2022-05-11 23:08:00" itemprop="dateModified" datetime="2022-05-11T23:08:00+08:00">2022-05-11</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="NIMA：Neural-Image-Assessment"><a href="#NIMA：Neural-Image-Assessment" class="headerlink" title="NIMA：Neural Image Assessment"></a>NIMA：Neural Image Assessment</h1><h2 id="1、introduction"><a href="#1、introduction" class="headerlink" title="1、introduction"></a>1、introduction</h2><ol>
<li><p>基于CNN的方法相比较早期基于手工制作的特征的做法，性能有显著的提升；</p>
</li>
<li><p>AVA 数据集，图片审美视觉分析的标准数据集；</p>
</li>
<li><p>深度CNN非常适合审美评估任务【1】【2】；他们的双列 CNN 由四个卷积层和两个全连接层组成，其输入是调整大小的图像和大小为 224 × 224 的裁剪窗口；</p>
</li>
<li><p>之前大多是通过分类或者回归的方法预测人类评估的分数；</p>
</li>
<li><p>kong【3】训练了一个基于 AlexNet 的 CNN 来学习两个输入图像的审美分数差异，从而间接优化排名相关性。</p>
</li>
<li><p>NIMA的目标是预测与人类评分的相关性，而不是将图片分类或者回归到平均分。提出了EMD loss，它显示了有序类分类的性能提升。实验也表明，这种方法也更准确地预测了平均分。</p>
</li>
</ol>
<h2 id=""><a href="#" class="headerlink" title=" "></a> </h2><h2 id="2、proposed-method"><a href="#2、proposed-method" class="headerlink" title="2、proposed method"></a>2、proposed method</h2><p>模型建立在图片分类模型的结构基础上。</p>
<p><img src="https://vino-1316924433.cos.ap-beijing.myqcloud.com/image-20231026114849878.png" alt="image-20231026114849878"></p>
<p>在训练阶段，输入图像被重新缩放为256<em>256，然后随机提取 224\</em>224的裁剪，这减少潜在的过度拟合问题。</p>
<h2 id="3、实验"><a href="#3、实验" class="headerlink" title="3、实验"></a>3、实验</h2><p>基线CNN权重通过在ImageNet上训练来初始化，最后一个全连接层是随机初始化。权重和偏置动量设置为0.9,基线CNN最后一层dropout应用0.75。基线CNN层和最后一个全连接层的学习率分别设置为3<em>10e-7,3\</em>10e-6。在基线CNN层上设置较低的学习率会导致使用sgd时更容易和更快优化。</p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>【1】Deep multi-patch aggregation network for image style, aesthetics, and quality estimation</p>
<p>【2】Rating image aesthetics using deep learning</p>
<p>【3】S. Kong, X. Shen, Z. Lin, R. Mech, and C. Fowlkes, “Photo aesthetics ranking network with attributes and content adaptation,” in European Conference on Computer Vision. Springer, 2016, pp. 662–679. 1, 2, 6, 7</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2022/04/19/Vit/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Jie Chu">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="CJ blog">
      <meta itemprop="description" content="日常笔记">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | CJ blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/04/19/Vit/" class="post-title-link" itemprop="url">VIT</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>
      

      <time title="Created: 2022-04-19 21:00:00 / Modified: 23:08:00" itemprop="dateCreated datePublished" datetime="2022-04-19T21:00:00+08:00">2022-04-19</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="ViT-Vision-Transformer"><a href="#ViT-Vision-Transformer" class="headerlink" title="ViT(Vision Transformer)"></a>ViT(Vision Transformer)</h1><h2 id="模型介绍"><a href="#模型介绍" class="headerlink" title="模型介绍"></a>模型介绍</h2><p>受到NLP领域中Transformer成功应用的启发，Vit算法中尝试将标准的Transformer结构直接应用于图像，并对整个图像分类流程进行最少的修改。</p>
<p><strong>Vit原论文中最核心的结论是，当拥有足够多的数据进行预训练的时候，ViT的表现就会超过CNN，突破Transformer的归纳偏置的限制，可以在下游任务中获得较好的迁移效果。</strong></p>
<p>但是当训练数据集不够大的时候，ViT的表现通常比同等大小的ResNets要差一些，因为Transformer和CNN相比缺少归纳偏置（inductive bias），即一种先验知识，提前做好的假设。CNN具有两种归纳偏置，一种是局部性（locality/two-dimensional neighborhood structure），即图片上相邻的区域具有相似的特征；一种是平移不变形（translation equivariance）， $f(g(x)=g(f(x)))$ ，其中g代表卷积操作，f代表平移操作。当CNN具有以上两种归纳偏置，就有了很多先验信息，需要相对少的数据就可以学习一个比较好的模型。</p>
<h2 id="模型结构与实现"><a href="#模型结构与实现" class="headerlink" title="模型结构与实现"></a>模型结构与实现</h2><p><img src="https://vino-1316924433.cos.ap-beijing.myqcloud.com/ViT.png" alt="图1 ViT算法结构示意图"></p>
<h3 id="1-图像分块嵌入"><a href="#1-图像分块嵌入" class="headerlink" title="1.图像分块嵌入"></a>1.图像分块嵌入</h3><p>transformer的输入是一个二维矩阵，因此在ViT算法中，首先要做的是如何将一个$H\times W\times C$ 的三维图像转换为$N\times D$ 的二维输入。</p>
<p>iT中的具体实现方式为：将 $H×W×C$ 的图像，变为一个 $N×(P^2\times C)$ 的序列。这个序列可以看作是一系列展平的图像块，也就是将图像切分成小块后，再将其展平。该序列中一共包含了 $N=HW/P^2$ 个图像块，每个图像块的维度则是 $(P^2\times C)$。其中 $P$ 是图像块的大小，$C$ 是通道数量。经过如上变换，就可以将 $N$ 视为sequence的长度了。</p>
<p>但是，此时每个图像块的维度是 $(P2\times C)$，而我们实际需要的向量维度是 $D$，因此我们还需要对图像块进行 Embedding。这里 Embedding 的方式非常简单，只需要对每个 $(P^2\times C)$的图像块做一个线性变换，将维度压缩为 $D$ 即可。</p>
<h3 id="2-多头注意力"><a href="#2-多头注意力" class="headerlink" title="2.多头注意力"></a>2.多头注意力</h3><p>将图像转换成序列之后，就可以将其输入到 Transformer 中结构中进行特征提取了。</p>
<p><img src="https://vino-1316924433.cos.ap-beijing.myqcloud.com/Multi-head_Attention.jpg" alt="图4 多头注意力"></p>
<h3 id="3-MLP"><a href="#3-MLP" class="headerlink" title="3.MLP"></a>3.MLP</h3><p><img src="https://vino-1316924433.cos.ap-beijing.myqcloud.com/MLP.png" alt="图7 多层感知机"></p>
<h3 id="4-DropPath"><a href="#4-DropPath" class="headerlink" title="4.DropPath"></a>4.DropPath</h3><p>除了以上重要模块意外，代码实现过程中还使用了DropPath（Stochastic Depth）来代替传统的Dropout结构，DropPath可以理解为一种特殊的 Dropout。其作用是在训练过程中随机丢弃子图层（randomly drop a subset of layers），而在预测时正常使用完整的 Graph。</p>
<p><strong>参考文献</strong>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2010.11929">An Image is Worth 16x16 Words:Transformers for Image Recognition at Scale</a></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2022/04/11/resnet/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Jie Chu">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="CJ blog">
      <meta itemprop="description" content="日常笔记">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | CJ blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/04/11/resnet/" class="post-title-link" itemprop="url">resnet解析</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2022-04-11 21:03:00" itemprop="dateCreated datePublished" datetime="2022-04-11T21:03:00+08:00">2022-04-11</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2023-04-11 23:03:00" itemprop="dateModified" datetime="2023-04-11T23:03:00+08:00">2023-04-11</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="resnet"><a href="#resnet" class="headerlink" title="resnet"></a>resnet</h1><h3 id="1-1-batch-normalization原理"><a href="#1-1-batch-normalization原理" class="headerlink" title="1.1 batch normalization原理"></a>1.1 batch normalization原理</h3><p>提出背景：在训练层数较深的神经网络时，参数的变化导致每一层的输入分布会发生变化，进而上层的网络需要不停地去适应这些分布变化，使得我们的模型训练变得困难——internal Covariate Shift</p>
<p>问题：上层网络需要不停调整来适应输入分布的变化，导致网络学习速度的降低；网络的训练过程容易陷入梯度饱和区，减缓网络收敛速度。</p>
<p>减缓internal covariate shift的方法：</p>
<ul>
<li>白化：对输入数据分布进行变换，具有相同的均值和方差；</li>
<li><strong>batch normalization</strong>：由于白化过程计算成本太高，且改变了网络每一层的分布。</li>
</ul>
<p><img src="https://vino-1316924433.cos.ap-beijing.myqcloud.com/image-20220701153501142.png" alt="image-20220701153501142"></p>
<p><img src="https://vino-1316924433.cos.ap-beijing.myqcloud.com/image-20220701153552148.png" alt="image-20220701153552148"></p>
<h3 id="1-2-resnet-结构"><a href="#1-2-resnet-结构" class="headerlink" title="1.2  resnet 结构"></a>1.2  resnet 结构</h3><p><img src="https://vino-1316924433.cos.ap-beijing.myqcloud.com/image-20220701154852179.png" alt="image-20220701154852179"></p>
<p><strong>Stage 0</strong></p>
<ul>
<li><code>(3,224,224)</code>指输入<code>INPUT</code>的通道数(channel)、高(height)和宽(width)，即<code>(C,H,W)</code>。现假设输入的高度和宽度相等，所以用<code>(C,W,W)</code>表示。</li>
<li>该stage中第1层包括3个先后操作</li>
</ul>
<ol>
<li><code>CONV</code><br> <code>CONV</code>是卷积（Convolution）的缩写，<code>7×7</code>指卷积核大小，<code>64</code>指<a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=卷积核&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra={&quot;sourceType&quot;%3A&quot;article&quot;%2C&quot;sourceId&quot;%3A&quot;353235794&quot;}">卷积核</a>的数量（即该卷积层输出的通道数），<code>/2</code>指卷积核的步长为2。</li>
<li><code>BN</code><br> <code>BN</code>是Batch Normalization的缩写，即常说的BN层。 </li>
<li><code>RELU</code><br> <code>RELU</code>指ReLU激活函数。</li>
</ol>
<ul>
<li><p>该stage中第2层为<code>MAXPOOL</code>，即最大池化层，其kernel大小为<code>3×3</code>、步长为<code>2</code>。</p>
</li>
<li><p><code>(64,56,56)</code>是该stage输出的通道数(channel)、高(height)和宽(width)，其中<code>64</code>等于该stage第1层卷积层中卷积核的数量，<code>56</code>等于<code>224/2/2</code>（步长为2会使输入尺寸减半）。 </p>
</li>
</ul>
<p>总体来讲，在<em>Stage 0</em>中，形状为<code>(3,224,224)</code>的输入先后经过卷积层、<a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=BN层&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra={&quot;sourceType&quot;%3A&quot;article&quot;%2C&quot;sourceId&quot;%3A&quot;353235794&quot;}">BN层</a>、ReLU激活函数、<a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=MaxPooling层&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra={&quot;sourceType&quot;%3A&quot;article&quot;%2C&quot;sourceId&quot;%3A&quot;353235794&quot;}">MaxPooling层</a>得到了形状为<code>(64,56,56)</code>的输出。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2022/03/20/Inception%E7%B3%BB%E5%88%97/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Jie Chu">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="CJ blog">
      <meta itemprop="description" content="日常笔记">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | CJ blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/03/20/Inception%E7%B3%BB%E5%88%97/" class="post-title-link" itemprop="url">Inception系列</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2022-03-20 11:03:00" itemprop="dateCreated datePublished" datetime="2022-03-20T11:03:00+08:00">2022-03-20</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2022-03-22 13:03:00" itemprop="dateModified" datetime="2022-03-22T13:03:00+08:00">2022-03-22</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="Inception"><a href="#Inception" class="headerlink" title="Inception"></a>Inception</h1><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>一般来说，提升神经网络性能最直接的办法就是增加网络的尺寸，包括增加网络的深度和宽度两个方面。但这种方式存在一些问题：</p>
<ol>
<li><p>参数太多，如果训练数据集有限，很容易产生过拟合；</p>
</li>
<li><p>网络越大，参数越多，计算复杂度越高，难以应用；</p>
</li>
<li><p>网络越深，容易出现梯度弥散问题，难以优化模型；</p>
</li>
</ol>
<h2 id="Inception-v1"><a href="#Inception-v1" class="headerlink" title="Inception-v1"></a>Inception-v1</h2><p>深度研究 Inception Net模型之前，必须了解 Inception 网络的一个重要概念：</p>
<p><strong>1×1卷积</strong>：1×1 卷积简单地将输入像素及其所有相应通道映射到输出像素。1×1卷积作为降维模块，一定程度上减少的计算量。</p>
<ul>
<li>例如，在不使用1×1卷积的情况下执行5×5卷积，如下所示：</li>
</ul>
<p><img title="" src="https://vino-1316924433.cos.ap-beijing.myqcloud.com/inceptionNet.png" alt="" data-align="center"></p>
<p>FLOPs运算次数：（14×14×48）×（5×5×480）= 112.9M</p>
<ul>
<li>使用 1×1 卷积：</li>
</ul>
<p><img src="https://vino-1316924433.cos.ap-beijing.myqcloud.com/inceptionNet2.png" title="" alt="" data-align="center"></p>
<p>FLOPs运算次数</p>
<p>1×1卷积的操作数= （14×14×16）×（1×1×480）=1.5M<br>5×5卷积的操作数= （14×14×48）×（5×5×16 ) = 3.8M<br>相加后，1.5M + 3.8M = 5.3M</p>
<p>因此1×1卷积可以帮助减少模型大小，这可以在某种程度上帮助减少过度拟合问题；</p>
<p><strong>降维初始模型</strong></p>
<p><img src="https://vino-1316924433.cos.ap-beijing.myqcloud.com/modified.png" title="" alt="" data-align="center"></p>
<h2 id="Inception-v2"><a href="#Inception-v2" class="headerlink" title="Inception v2"></a>Inception v2</h2><h3 id="Inception-v1架构的问题"><a href="#Inception-v1架构的问题" class="headerlink" title="Inception v1架构的问题"></a>Inception v1架构的问题</h3><p>Inception V1有时会使用5×5等卷积，导致输入维度大幅下降。这导致神经网络使用一些精度下降。其背后的原因是，如果输入维度下降得太快，神经网络容易丢失信息。 此外，与3×3相比，<br>当我们使用更大的卷积（如5×5 ）时，复杂度也会降低. 我们可以在因式分解方面走得更远，即我们可以将3×3卷积分成<strong>1×3</strong>的非对称卷积，然后是3×1卷积。这相当于滑动一个具有与3×3卷积相同感受野但比*3×3便宜33%的两层网络。当输入维度很大但仅当输入大小为mxm时，这种分解不适用于早期层（m 在 12 到 20 之间）。根据 Inception V1 架构，辅助分类器提高了网络的收敛性。他们认为，通过将有用的梯度推到较早的层（以减少损失），它可以帮助减少深层网络中梯度消失问题的影响。但是，这篇论文的作者发现这个分类器在训练的早期并没有很好地提高收敛性。</p>
<h3 id="Batch-Normalization"><a href="#Batch-Normalization" class="headerlink" title="Batch Normalization"></a>Batch Normalization</h3><p>在BN的论文里，作者提出了Internal Covariate Shift这个问题，即在训练神经网络的过程中，因为前一层的参数变化而导致每层的输入分布都在不断变化（the distribution of each layer’s inputs changes during training, as the parameters of the previous layers change）。这使得我们需要更低的学习率和更小心地进行参数初始化，导致我们难以充分构建一个具有饱满地非线性结构的模型，而这个现象就被称作Internal Covariate Shift。为了解决这个问题，Google提出了Batch Normalization（批规范化）。即在每次梯度下降前，对每个mini-batch做归一化操作来降低数据分布的影响。</p>
<h3 id="小卷积和代替大卷积核"><a href="#小卷积和代替大卷积核" class="headerlink" title="小卷积和代替大卷积核"></a>小卷积和代替大卷积核</h3><p><img title="" src="https://vino-1316924433.cos.ap-beijing.myqcloud.com/5x5replaced3x3.png" alt="灯箱" data-align="center"></p>
<p>该架构还将 nXn 分解转换为<em>1xn</em>和 nx1 分解。正如我们上面讨论的，3×3 卷积可以转换为<em>1×3 ，然后是 3×1 卷积，与<em>*3×3</em></em>相比，计算复杂度降低了 33% 。</p>
<p><img title="" src="https://vino-1316924433.cos.ap-beijing.myqcloud.com/1xn.png" alt="灯箱" data-align="center"></p>
<h2 id="Inception-v3"><a href="#Inception-v3" class="headerlink" title="Inception v3"></a>Inception v3</h2><p>Inception v3 类似于 Inception v2，并做了以下改动：</p>
<ul>
<li><p>使用 RMSprop 优化器；</p>
</li>
<li><p>辅助分类器全连接层的BN；</p>
</li>
<li><p>使用 7×7 分解卷积；</p>
</li>
</ul>
<h2 id="Inception-v4"><a href="#Inception-v4" class="headerlink" title="Inception v4"></a>Inception v4</h2><p>将 Inception 模块和残差连接 结合起来。</p>
<p><img src="https://vino-1316924433.cos.ap-beijing.myqcloud.com/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA57qi6bKk6bG85LiO57u_6am0,size_20,color_FFFFFF,t_70,g_se,x_16.png" alt=""></p>
<p>EmbOding!9196#CN360</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>





</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2024</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">Jie Chu</span>
  </div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/muse/" rel="noopener" target="_blank">NexT.Muse</a>
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script>

  






  




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>



</body>
</html>
